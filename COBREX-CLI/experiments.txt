1. Human Vs Computer based recognised rules
Ex1:
POKER.cbl
- One of the golden truth for POKER is like:

    PERFORM VARYING I FROM 2 BY 1 UNTIL I > 6
        IF CARD-VALUE (I) NOT = CARD-VALUE (I - 1) + 1 
        AND NOT (CARD-VALUE (I) = "A" 
        AND CARD-VALUE (I - 1) = "5")
            EXIT SECTION
        END-IF
    END-PERFORM
    MOVE ONE TO STRAIGHT-FLAG.

But a human can know that this is a validation for STRAIGHT-FLAG and move one to it but not a static analysis can figure out.

Ex2:
IN CARRENT.cbl
- We are realising the entire evaluate as one rule in the algorithm as each when just have an atomic unit based on the same value so it make sense to assume that
no complex calculations are happening but as we could see that because it is cartype it makes sense to realise each of the when in a fragmented manner.

2. Two cases where the unaddressed constructs are not contributing the rule

Ex:1 (high precision)
- Like in the ATM example, we can see that the list of unaddressed constructs are {list} but as we can see that still the recall for the same is 100, as we can clearly observe that
as for subtract as the entire para is being triggered by when to become a rule, there is no relevance of it being individually recognised and dealt with, (we tried to merge it sequentially but could not merge because of lack of commonality).
Same goes with add as well. Other constructs like stop and continue need not be explicitly addressed as they are just determining the flow already been captured by the flow graph.
// Discard evaluate as our implementation is considering evaluate and when as two different constructs we realised it like this, but they are covered.

Ex:2 (low precision)
- In the example of TICTACTOBOL we are not specifically addressing read, open, close initialise etc constructs but even if we address them we won't be able to much of difference as they are not
the significant contributors to the rule, they just the i/o operations that are happening along side.

3. Two cases when the unaddressed rules are contributing to the rule

Ex1: (high precision)
In eleve.cob, we aere not addressing some reads and computes coming due to them, they donot satisfy our candidate structure so if we are able to realise them 
then we could actually fetch better results.

Ex2: (low precision)
LOANPYMT.cbl as we are just able to capture only the conditional types of rules we could not capture the computational rule here, they are getting encapsulated under an atomic unit but that is not 
enough it needs to be recognised as a rule.

4. Measuring the coverage of the business rules based on the golden truth in terms of LOCs per rule
= We would be see the percentage based on (# of lines that are extracted as a part of rule {these lines can span over multiple extracted rules} / Total lines in the relevant Golden Truth)

Ex1: POKER.cbl (low recall) || We can give example of AESMAIN as well which also has a similar case
- R1: 12/12
- R2: 12/15
- R3: 7/8   (we counted this to be a correct rule though as it was just one line)
- R4: 5/6   (we counted this to be a correct rule though as it was just one line)
- R5: 5/5   (Realised as a bigger set though)
- R6-10,12: 2/2 (Realised as a bigger set though)
- R11: 4/4  (Realised as a bigger set though)
Number of lines of all GT = 58
Number of lines of extracted rule = 53
= 91.37 %
